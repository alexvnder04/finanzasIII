{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valoración de Activos - Recomendación para un perfil Adverso Al Riesgo - Finanzas III \n",
    "📎📈📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profe, instale esto para que el código corra correctamente: pip install yfinance pandas numpy matplotlib seaborn statsmodels\n",
    "\n",
    "#Integrantes:\n",
    "\n",
    "# - Aylen Alvarado\n",
    "# - Solange Donoso\n",
    "# - Alan Espinoza\n",
    "# - Sebastián Pizarro \n",
    "\n",
    "#Profesor:\n",
    "\n",
    "# - Sergio Álvarez \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descargando precios...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alana\\AppData\\Local\\Temp\\ipykernel_27876\\558691733.py:38: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(list(tickers.values()), start=start_date, end=end_date)\n",
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando IPSA desde archivo local...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'S&P IPSA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------------------------------------------------- #\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# CARGAR IPSA / 2014 - 2024 \u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------------------------------------------------- #\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCargando IPSA desde archivo local...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m ipsa_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mS&P IPSA.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m ipsa = ipsa_df[[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m]].dropna()\n\u001b[32m     55\u001b[39m ipsa = ipsa.set_index(\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'S&P IPSA.csv'"
     ]
    }
   ],
   "source": [
    "# === ANALISIS FINANCIERO PARA EMPRESAS CHILENAS ===\n",
    "# Descarga de datos, estadisticas descriptivas, retornos, betas y portafolios\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# CONFIGURACION INICIAL\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "tickers = {\n",
    "    'AGUAS-A': 'AGUAS-A.SN',\n",
    "    'ANDINA-B': 'ANDINA-B.SN',\n",
    "    'BSANTANDER': 'BSANTANDER.SN',\n",
    "    'CAP': 'CAP.SN',\n",
    "    'CENCOSUD': 'CENCOSUD.SN',\n",
    "    'CMPC': 'CMPC.SN',\n",
    "    'CONCHATORO': 'CONCHATORO.SN',\n",
    "    'ECL': 'ECL.SN',\n",
    "    'ENELCHILE': 'ENELCHILE.SN',\n",
    "    'FALABELLA': 'FALABELLA.SN'\n",
    "}\n",
    "\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# DESCARGAR DATOS\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "print(\"\\nDescargando precios...\")\n",
    "data = yf.download(list(tickers.values()), start=start_date, end=end_date)\n",
    "\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    close_prices = data['Close']\n",
    "else:\n",
    "    close_prices = data.to_frame(name='Close')\n",
    "\n",
    "close_prices.columns = tickers.keys()\n",
    "close_prices = close_prices.sort_index()\n",
    "close_prices.to_csv(\"precios_empresas_chilenas.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# CARGAR IPSA / 2014 - 2024 \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Cargando IPSA desde archivo local...\")\n",
    "ipsa_df = pd.read_csv(\"S&P IPSA.csv\", sep=\",\", quotechar='\"', parse_dates=[\"Date\"], dayfirst=True)\n",
    "ipsa = ipsa_df[['Date', 'Price']].dropna()\n",
    "ipsa = ipsa.set_index('Date')\n",
    "ipsa['Price'] = ipsa['Price'].str.replace(',', '')\n",
    "ipsa['Price'] = ipsa['Price'].astype(float)\n",
    "ipsa = ipsa.sort_index()\n",
    "ipsa = ipsa['Price']\n",
    "ipsa.name = 'IPSA'\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# ESTADISTICA DESCRIPTIVA\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"\\nCalculando estadística descriptiva...\")\n",
    "descriptive_stats = close_prices.describe().T\n",
    "descriptive_stats['skewness'] = close_prices.skew()\n",
    "descriptive_stats['kurtosis'] = close_prices.kurt()\n",
    "descriptive_stats.to_csv(\"estadistica_descriptiva.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# RETORNOS\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Calculando retornos...\")\n",
    "daily_returns = close_prices.pct_change().dropna()\n",
    "annual_returns = (1 + daily_returns).resample('Y').prod() - 1\n",
    "close_prices.to_csv(\"precios_diarios_ordenados.csv\")\n",
    "daily_returns.to_csv(\"retornos_diarios.csv\")\n",
    "annual_returns.to_csv(\"retornos_anuales.csv\")\n",
    "descriptive_stats['mediana'] = daily_returns.median()\n",
    "descriptive_stats.to_csv(\"estadistica_descriptiva_extendida.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# BETAS\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Calculando betas...\")\n",
    "ret_ip = ipsa.pct_change().dropna()\n",
    "betas = {}\n",
    "\n",
    "for col in daily_returns.columns:\n",
    "    df = pd.concat([daily_returns[col], ret_ip], axis=1).dropna()\n",
    "    df.columns = ['Ri', 'Rm']\n",
    "    X = sm.add_constant(df['Rm'])\n",
    "    model = sm.OLS(df['Ri'], X).fit()\n",
    "    betas[col] = model.params['Rm']\n",
    "\n",
    "betas_df = pd.DataFrame.from_dict(betas, orient='index', columns=['Beta'])\n",
    "betas_df.to_csv(\"betas.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# PORTAFOLIOS\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Construyendo portafolios...\")\n",
    "mean_returns = daily_returns.mean() * 252\n",
    "cov_matrix = daily_returns.cov() * 252\n",
    "correlation_matrix = daily_returns.corr()\n",
    "\n",
    "n_portfolios = 20000\n",
    "results = {'Return': [], 'Volatility': [], 'Sharpe': [], 'Weights': []}\n",
    "\n",
    "for _ in range(n_portfolios):\n",
    "    weights = np.random.random(len(tickers))\n",
    "    weights /= np.sum(weights)\n",
    "    port_return = np.dot(weights, mean_returns)\n",
    "    port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = port_return / port_volatility\n",
    "    results['Return'].append(port_return)\n",
    "    results['Volatility'].append(port_volatility)\n",
    "    results['Sharpe'].append(sharpe_ratio)\n",
    "    results['Weights'].append(weights)\n",
    "    port_daily_returns = daily_returns.dot(weights)\n",
    "    port_median_annual = port_daily_returns.median() * 252\n",
    "    results.setdefault('MedianReturn', []).append(port_median_annual)\n",
    "    \n",
    "portfolios_df = pd.DataFrame(results)\n",
    "portfolios_df.to_csv(\"portafolios_simulados_con_mediana.csv\")\n",
    "\n",
    "# Identificar el portafolio con mejor Sharpe \n",
    "max_sharpe_idx = portfolios_df['Sharpe'].idxmax()\n",
    "portafolio_optimo = portfolios_df.iloc[max_sharpe_idx]\n",
    "\n",
    "print(\"\\nPortafolio recomendado (máximo Sharpe):\")\n",
    "print(portafolio_optimo)\n",
    "\n",
    "# Guardar portafolio óptimo en CSV\n",
    "portafolio_optimo.to_csv(\"portafolio_recomendado.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# GRAFICOS ADICIONALES\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Generando gráficos adicionales...\")\n",
    "\n",
    "# 1. Comparación Portafolio Conservador vs IPSA\n",
    "portafolio_conservador_ret = daily_returns.dot(results['Weights'][np.argmax(results['Sharpe'])])\n",
    "portafolio_conservador_ret.name = 'Portafolio Conservador'\n",
    "portafolio_conservador_idx = (1 + portafolio_conservador_ret).cumprod() * 100\n",
    "ipsa_idx = (1 + ret_ip).cumprod() * 100\n",
    "comparacion_df = pd.concat([portafolio_conservador_idx, ipsa_idx], axis=1).dropna()\n",
    "comparacion_df.columns = ['Portafolio Conservador', 'IPSA']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(comparacion_df.index, comparacion_df['Portafolio Conservador'], label='Portafolio Conservador', linewidth=2)\n",
    "plt.plot(comparacion_df.index, comparacion_df['IPSA'], label='IPSA', linewidth=2, linestyle='--', color='black')\n",
    "plt.title(\"Crecimiento Acumulado: Portafolio Conservador vs IPSA (Base 100)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Índice de Crecimiento\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparacion_portafolio_conservador_vs_ipsa.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Evolución acumulada acciones vs IPSA\n",
    "acumulados = (1 + daily_returns).cumprod() * 100\n",
    "acumulados['IPSA'] = (1 + ret_ip).cumprod() * 100\n",
    "plt.figure(figsize=(12, 7))\n",
    "for ticker in tickers.keys():\n",
    "    plt.plot(acumulados.index, acumulados[ticker], label=ticker)\n",
    "plt.plot(acumulados.index, acumulados['IPSA'], label='IPSA', linewidth=3, color='black', linestyle='--')\n",
    "plt.title(\"Evolución Acumulada del Retorno: Acciones vs IPSA (Base 100)\")\n",
    "plt.ylabel(\"Índice de Crecimiento\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"evolucion_precios_acciones_ipsa.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Mapa de calor de volatilidad anual\n",
    "vol_anual = daily_returns.resample('Y').std() * np.sqrt(252)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(vol_anual.T, cmap=\"YlOrRd\", annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Volatilidad Anual por Acción (Heatmap)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"volatilidad_anual_heatmap.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Beta vs Volatilidad\n",
    "volatilidades = daily_returns.std() * np.sqrt(252)\n",
    "beta_vol = pd.DataFrame({\n",
    "    'Volatilidad': volatilidades,\n",
    "    'Beta': betas_df['Beta']\n",
    "})\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=beta_vol, x='Volatilidad', y='Beta', hue=beta_vol.index, s=100)\n",
    "plt.axhline(1, color='gray', linestyle='--')\n",
    "plt.axvline(volatilidades.mean(), color='gray', linestyle='--')\n",
    "plt.title(\"Beta vs. Volatilidad Anual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"beta_vs_volatilidad.png\")\n",
    "plt.close()\n",
    "\n",
    "# 5. Correlación Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlacion_heatmap.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "#6. Frontera Eficiente con Mínimo Riesgo\n",
    "min_vol_idx = portfolios_df['Volatility'].idxmin()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(portfolios_df['Volatility'], portfolios_df['Return'], c=portfolios_df['Sharpe'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.scatter(portfolios_df.loc[min_vol_idx, 'Volatility'], portfolios_df.loc[min_vol_idx, 'Return'], color='red', label='Min Var')\n",
    "plt.scatter(volatilidades.mean(), mean_returns.mean(), color='black', marker='x', label='IPSA Aprox')\n",
    "plt.title(\"Frontera Eficiente con Portafolio de Varianza Mínima e IPSA\")\n",
    "plt.xlabel(\"Volatilidad Anual\")\n",
    "plt.ylabel(\"Retorno Esperado Anual\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"frontera_eficiente_con_min_var_y_ipsa.png\")\n",
    "plt.close()\n",
    "\n",
    "#7. Generar gráfico de barras con los Betas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=betas_df.index, y=betas_df['Beta'], palette='viridis')\n",
    "plt.axhline(1, color='red', linestyle='--', label='Beta = 1 (Mercado)')\n",
    "plt.title('Betas de las Acciones respecto al IPSA')\n",
    "plt.ylabel('Beta')\n",
    "plt.xlabel('Acción')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"betas_barplot.png\")\n",
    "plt.close()\n",
    "\n",
    "#8. Retorno vs Riesgo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(volatilidades, mean_returns, s=100)\n",
    "for i, txt in enumerate(mean_returns.index):\n",
    "    plt.annotate(txt, (volatilidades[i], mean_returns[i]))\n",
    "plt.title(\"Retorno Esperado vs. Riesgo (Volatilidad Anual)\")\n",
    "plt.xlabel(\"Volatilidad Anual\")\n",
    "plt.ylabel(\"Retorno Esperado Anual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"retorno_vs_riesgo_acciones.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# RECOMENDACIÓN DE PORTAFOLIO PARA PERFIL ADVERSO AL RIESGO\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# Criterio: Menor volatilidad con Sharpe ratio mayor a la media\n",
    "sharpe_mean = portfolios_df['Sharpe'].mean()\n",
    "filtrados = portfolios_df[portfolios_df['Sharpe'] > sharpe_mean]\n",
    "portafolio_recomendado = filtrados.loc[filtrados['Volatility'].idxmin()]\n",
    "\n",
    "# Extraer pesos en un dataframe legible\n",
    "pesos_df = pd.DataFrame(\n",
    "    data=[portafolio_recomendado['Weights']],\n",
    "    columns=tickers.keys()\n",
    ")\n",
    "pesos_df['Retorno Esperado'] = portafolio_recomendado['Return']\n",
    "pesos_df['Volatilidad'] = portafolio_recomendado['Volatility']\n",
    "pesos_df['Sharpe Ratio'] = portafolio_recomendado['Sharpe']\n",
    "pesos_df.to_csv(\"portafolio_recomendado.csv\", index=False)\n",
    "\n",
    "# Imprimir resumen en consola\n",
    "print(\"\\n📌 Portafolio recomendado para perfil adverso al riesgo:\")\n",
    "print(pesos_df.T)\n",
    "\n",
    "# Comparar gráficamente con IPSA\n",
    "print(\"Generando gráfico comparativo con IPSA...\")\n",
    "\n",
    "ret_portafolio_recomendado = daily_returns.dot(portafolio_recomendado['Weights'])\n",
    "ret_portafolio_recomendado.name = 'Portafolio Recomendado'\n",
    "idx_portafolio = (1 + ret_portafolio_recomendado).cumprod() * 100\n",
    "idx_ipsa = (1 + ret_ip).cumprod() * 100\n",
    "\n",
    "comparacion_recomendado = pd.concat([idx_portafolio, idx_ipsa], axis=1).dropna()\n",
    "comparacion_recomendado.columns = ['Portafolio Recomendado', 'IPSA']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(comparacion_recomendado.index, comparacion_recomendado['Portafolio Recomendado'], label='Portafolio Recomendado', linewidth=2)\n",
    "plt.plot(comparacion_recomendado.index, comparacion_recomendado['IPSA'], label='IPSA', linestyle='--', color='black', linewidth=2)\n",
    "plt.title(\"Comparación Portafolio Recomendado vs IPSA (Base 100)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Índice de Crecimiento\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparacion_portafolio_recomendado_vs_ipsa.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# GUARDAR PORTAFOLIOS CLAVE EN CSV\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# Portafolio de máxima Sharpe\n",
    "max_sharpe_idx = portfolios_df['Sharpe'].idxmax()\n",
    "max_sharpe = portfolios_df.loc[max_sharpe_idx].copy()\n",
    "max_sharpe_weights = pd.Series(\n",
    "    [round(w, 4) for w in results['Weights'][max_sharpe_idx]],\n",
    "    index=tickers.keys()\n",
    ")\n",
    "max_sharpe_weights.name = \"Peso\"\n",
    "max_sharpe_weights.to_csv(\"portafolio_max_sharpe.csv\")\n",
    "\n",
    "# Portafolio de mínima varianza\n",
    "\n",
    "min_var_idx = portfolios_df['Volatility'].idxmin()\n",
    "min_var = portfolios_df.loc[min_var_idx].copy()\n",
    "min_var_weights = pd.Series(\n",
    "    [round(w, 4) for w in results['Weights'][min_var_idx]],\n",
    "    index=tickers.keys()\n",
    ")\n",
    "min_var_weights.name = \"Peso\"\n",
    "min_var_weights.to_csv(\"portafolio_min_varianza.csv\")\n",
    "\n",
    "print(\"✅ Portafolios clave guardados como CSV.\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# RENDIMIENTO, VOLATILIDAD Y SHARPE DE PORTAFOLIOS CLAVE Y COMPARACION CON IPSA\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# Función para calcular métricas del portafolio dada su ponderación\n",
    "def calc_metrics(weights, mean_returns, cov_matrix):\n",
    "    port_return = np.dot(weights, mean_returns)\n",
    "    port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = port_return / port_volatility\n",
    "    return port_return, port_volatility, sharpe_ratio\n",
    "\n",
    "# Calcular métricas para portafolio máxima Sharpe\n",
    "max_sharpe_return, max_sharpe_vol, max_sharpe_sharpe = calc_metrics(\n",
    "    results['Weights'][max_sharpe_idx], mean_returns, cov_matrix\n",
    ")\n",
    "\n",
    "# Calcular métricas para portafolio mínima varianza\n",
    "min_var_return, min_var_vol, min_var_sharpe = calc_metrics(\n",
    "    results['Weights'][min_var_idx], mean_returns, cov_matrix\n",
    ")\n",
    "\n",
    "# Calcular métricas para IPSA (anualizados)\n",
    "ipsa_return = ret_ip.mean() * 252\n",
    "ipsa_vol = ret_ip.std() * np.sqrt(252)\n",
    "ipsa_sharpe = ipsa_return / ipsa_vol\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "comparacion = pd.DataFrame({\n",
    "    'Rendimiento Anual': [max_sharpe_return, min_var_return, ipsa_return],\n",
    "    'Volatilidad Anual': [max_sharpe_vol, min_var_vol, ipsa_vol],\n",
    "    'Sharpe Ratio': [max_sharpe_sharpe, min_var_sharpe, ipsa_sharpe]\n",
    "}, index=['Max Sharpe', 'Min Varianza', 'IPSA'])\n",
    "\n",
    "comparacion.to_csv(\"comparacion_portafolios_ipsa.csv\")\n",
    "\n",
    "print(\"✅ Métricas de portafolios clave y comparación con IPSA guardadas.\")\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 1. CÁLCULO Y GRÁFICO DEL DRAWDOWN MÁXIMO\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "def max_drawdown(serie_precios):\n",
    "    \"\"\"Calcula el drawdown máximo de una serie de precios.\"\"\"\n",
    "    roll_max = serie_precios.cummax()\n",
    "    drawdown = (serie_precios - roll_max) / roll_max\n",
    "    max_dd = drawdown.min()\n",
    "    return drawdown, max_dd\n",
    "\n",
    "# Calcular drawdown para IPSA y portafolio óptimo (máximo Sharpe)\n",
    "portafolio_optimo_weights = portfolios_df.loc[portfolios_df['Sharpe'].idxmax(), 'Weights']\n",
    "portafolio_optimo_ret = daily_returns.dot(portafolio_optimo_weights)\n",
    "portafolio_optimo_idx = (1 + portafolio_optimo_ret).cumprod() * 100\n",
    "\n",
    "drawdown_ipsa, max_dd_ipsa = max_drawdown(ipsa_idx)\n",
    "drawdown_portafolio, max_dd_portafolio = max_drawdown(portafolio_optimo_idx)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(drawdown_ipsa.index, drawdown_ipsa, label=f'Drawdown IPSA (Max: {max_dd_ipsa:.2%})')\n",
    "plt.plot(drawdown_portafolio.index, drawdown_portafolio, label=f'Drawdown Portafolio Óptimo (Max: {max_dd_portafolio:.2%})')\n",
    "plt.title('Drawdown Máximo: IPSA vs Portafolio Óptimo')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"drawdown_ipsa_vs_portafolio.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 2. ANÁLISIS DE CORRELACIÓN DETALLADO\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "correlation_matrix = daily_returns.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlación entre Acciones\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matriz_correlacion_acciones.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 3. PORTAFOLIO DE MÍNIMA VARIANZA\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "min_var_idx = portfolios_df['Volatility'].idxmin()\n",
    "min_var_weights = portfolios_df.loc[min_var_idx, 'Weights']\n",
    "min_var_return = portfolios_df.loc[min_var_idx, 'Return']\n",
    "min_var_volatility = portfolios_df.loc[min_var_idx, 'Volatility']\n",
    "\n",
    "print(f\"Portafolio mínima varianza: Retorno esperado {min_var_return:.2%}, Volatilidad {min_var_volatility:.2%}\")\n",
    "\n",
    "# Guardar pesos mínimos varianza en CSV\n",
    "min_var_weights_df = pd.DataFrame(min_var_weights, index=tickers.keys(), columns=['Peso'])\n",
    "min_var_weights_df.to_csv(\"portafolio_minima_varianza.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 4. SIMULACIONES DE ESTRÉS (Días con mayor caída IPSA)\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# Seleccionar los 10 días con mayor caída diaria IPSA\n",
    "ipsa_daily_ret = ipsa.pct_change().dropna()\n",
    "peores_dias = ipsa_daily_ret.nsmallest(10)\n",
    "\n",
    "print(\"\\n10 días con mayor caída en IPSA:\")\n",
    "print(peores_dias)\n",
    "\n",
    "# Visualizar efecto de esos días en portafolio mínimo varianza\n",
    "ret_min_var_portafolio = daily_returns.dot(min_var_weights)\n",
    "impacto_dias_estres = ret_min_var_portafolio.loc[peores_dias.index]\n",
    "\n",
    "print(\"\\nImpacto en portafolio mínima varianza en esos días:\")\n",
    "print(impacto_dias_estres)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 5. GRÁFICOS DE SHARPE RATIO Y RECOMENDACIONES\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(portfolios_df['Sharpe'], bins=50, kde=True)\n",
    "plt.axvline(portfolios_df['Sharpe'].max(), color='red', linestyle='--', label='Máximo Sharpe')\n",
    "plt.title('Distribución del Sharpe Ratio de Portafolios Simulados')\n",
    "plt.xlabel('Sharpe Ratio')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sharpe_ratio_histograma.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# SHARPE RATIO: PORTAFOLIO VS IPSA\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"\\nCalculando Sharpe Ratio comparado...\")\n",
    "\n",
    "# Tasa libre de riesgo aproximada (puedes cambiarla si te dan una)\n",
    "risk_free_rate = 0.05\n",
    "\n",
    "# Retornos diarios\n",
    "# Alinear los índices para evitar KeyError\n",
    "common_idx = daily_returns.index.intersection(ipsa.pct_change().dropna().index)\n",
    "ret_port = daily_returns.loc[common_idx].dot(weights)\n",
    "ret_ip = ipsa.pct_change().dropna().loc[common_idx]\n",
    "\n",
    "# Sharpe diario\n",
    "sharpe_port = (ret_port.mean() - risk_free_rate) / ret_port.std()\n",
    "sharpe_ipsa = (ret_ip.mean() - risk_free_rate) / ret_ip.std()\n",
    "\n",
    "# Anualizado\n",
    "sharpe_port_annual = sharpe_port * np.sqrt(252)\n",
    "sharpe_ipsa_annual = sharpe_ipsa * np.sqrt(252)\n",
    "\n",
    "# Mostrar\n",
    "print(f\"📈 Sharpe Ratio Portafolio Conservador (anual): {sharpe_port_annual:.2f}\")\n",
    "print(f\"📉 Sharpe Ratio IPSA (anual): {sharpe_ipsa_annual:.2f}\")\n",
    "\n",
    "# Comparación Portafolio con Mayor Mediana vs IPSA\n",
    "print(\"Generando gráfico de comparación con portafolio mediana...\")\n",
    "\n",
    "idx_median_max = portfolios_df['MedianReturn'].idxmax()\n",
    "weights_median_max = portfolios_df.iloc[idx_median_max]['Weights']\n",
    "portafolio_median_ret = daily_returns.dot(weights_median_max)\n",
    "portafolio_median_ret.name = 'Portafolio Mediana'\n",
    "portafolio_median_idx = (1 + portafolio_median_ret).cumprod() * 100\n",
    "portafolio_median_idx.name = 'Portafolio Mediana'\n",
    "\n",
    "comparacion_mediana_df = pd.concat([portafolio_median_idx, ipsa_idx], axis=1).dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(comparacion_mediana_df.index, comparacion_mediana_df['Portafolio Mediana'], label='Portafolio Mediana', linewidth=2)\n",
    "plt.plot(comparacion_mediana_df.index, comparacion_mediana_df['IPSA'], label='IPSA', linestyle='--', linewidth=2, color='black')\n",
    "plt.title(\"Crecimiento Acumulado: Portafolio con Mayor Mediana vs IPSA (Base 100)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Índice de Crecimiento\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparacion_portafolio_mediana_vs_ipsa.png\")\n",
    "plt.close()\n",
    "\n",
    "# Recomendación simple basada en Sharpe ratio y volatilidad para inversor adverso al riesgo\n",
    "print(f\"\\nRecomendación para inversor adverso al riesgo:\")\n",
    "print(f\"- Portafolio mínima varianza con retorno esperado {min_var_return:.2%} y volatilidad {min_var_volatility:.2%}.\")\n",
    "print(\"- Este portafolio busca minimizar la volatilidad, ideal para quien quiere menor riesgo.\")\n",
    "print(f\"- Portafolio óptimo con máximo Sharpe ratio tiene retorno esperado {portfolios_df['Return'].max():.2%} y volatilidad {portfolios_df.loc[portfolios_df['Sharpe'].idxmax(),'Volatility']:.2%}.\")\n",
    "print(\"- Este portafolio maximiza la rentabilidad ajustada por riesgo, pero con más volatilidad.\")\n",
    "\n",
    "print(\"✅ Análisis adicionales, gráficos y reporte generado correctamente.\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# EXPORTAR MATRICES Y CVAR                                                                              \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "correlation_matrix.to_csv(\"matriz_correlacion.csv\")\n",
    "cov_matrix.to_csv(\"matriz_varianza_covarianza.csv\")\n",
    "\n",
    "confidence_level = 0.95\n",
    "cvar_diario = daily_returns.apply(lambda x: x[x <= x.quantile(1 - confidence_level)].mean())\n",
    "cvar_diario.name = 'CVaR Diario 95%'\n",
    "cvar_diario.to_csv(\"cvar_diario_95.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# RECOMENDACION DE PORTAFOLIO PARA PERFIL ADVERSO AL RIESGO                                             \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# Índice del portafolio conservador (mínima varianza)\n",
    "idx_min_var = np.argmin(portfolios_df['Volatility'])\n",
    "pesos_min_var = portfolios_df.loc[idx_min_var, 'Weights']\n",
    "\n",
    "# Beta ponderada del portafolio conservador\n",
    "beta_ponderada = 0\n",
    "for i, ticker in enumerate(tickers.keys()):\n",
    "    beta_ponderada += pesos_min_var[i] * betas_df.loc[ticker, 'Beta']\n",
    "\n",
    "# Retorno esperado y volatilidad del portafolio conservador\n",
    "retorno_min_var = portfolios_df.loc[idx_min_var, 'Return']\n",
    "vol_min_var = portfolios_df.loc[idx_min_var, 'Volatility']\n",
    "sharpe_min_var = portfolios_df.loc[idx_min_var, 'Sharpe']\n",
    "\n",
    "# Guardar recomendación en archivo txt\n",
    "ruta_recomendacion = \"recomendacion_portafolio_adverso.txt\"\n",
    "with open(ruta_recomendacion, 'w') as f:\n",
    "    f.write(\"Recomendación para Inversionista Adverso al Riesgo\\n\")\n",
    "    f.write(\"==================================================\\n\\n\")\n",
    "    f.write(f\"Portafolio conservador seleccionado: Portafolio de mínima varianza\\n\\n\")\n",
    "    f.write(f\"Retorno esperado anual: {retorno_min_var * 100:.2f}%\\n\")\n",
    "    f.write(f\"Volatilidad anual (riesgo): {vol_min_var * 100:.2f}%\\n\")\n",
    "    f.write(f\"Ratio de Sharpe: {sharpe_min_var:.3f}\\n\")\n",
    "    f.write(f\"Beta ponderada del portafolio: {beta_ponderada:.3f}\\n\\n\")\n",
    "    f.write(\"Composición del portafolio (pesos en %):\\n\")\n",
    "    for i, ticker in enumerate(tickers.keys()):\n",
    "        f.write(f\" - {ticker}: {pesos_min_var[i] * 100:.2f}%\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Interpretación:\\n\")\n",
    "    f.write(\"- Este portafolio busca minimizar la volatilidad, ideal para perfiles adversos al riesgo.\\n\")\n",
    "    f.write(\"- Su beta ponderada menor a 1 indica menor sensibilidad a los movimientos del mercado (IPSA).\\n\")\n",
    "    f.write(\"- Aunque el retorno esperado es más bajo que portafolios más arriesgados, la reducción del riesgo puede proteger el capital.\\n\")\n",
    "    f.write(\"- El ratio de Sharpe muestra una buena relación retorno-riesgo para este perfil.\\n\")\n",
    "    f.write(\"\\nSe recomienda revisar periódicamente este portafolio para ajustarlo según las condiciones del mercado.\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"✅ Archivo de recomendación generado en: {ruta_recomendacion}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 1. Simulación de escenarios Monte Carlo para portafolio recomendado                                   \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Simulando escenarios Monte Carlo para portafolio recomendado...\")\n",
    "\n",
    "n_simulaciones = 1000\n",
    "dias_sim = 252  # 1 año de trading\n",
    "pesos_optimos = portfolios_df.loc[portfolios_df['Sharpe'].idxmax(), 'Weights']  # Mejor portafolio Sharpe\n",
    "\n",
    "# Simulación de retornos diarios multivariados\n",
    "mean_daily_ret = daily_returns.mean()\n",
    "cov_daily = daily_returns.cov()\n",
    "\n",
    "resultados_mc = np.zeros((dias_sim, n_simulaciones))\n",
    "\n",
    "for i in range(n_simulaciones):\n",
    "    retornos_sim = np.random.multivariate_normal(mean_daily_ret, cov_daily, dias_sim)\n",
    "    # Calculo de serie de precios (asumiendo base 100)\n",
    "    precios_sim = 100 * np.cumprod(1 + np.dot(retornos_sim, pesos_optimos))\n",
    "    resultados_mc[:, i] = precios_sim\n",
    "\n",
    "# Graficar simulaciones\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(resultados_mc, color='grey', alpha=0.1)\n",
    "plt.title('Simulación Monte Carlo: Escenarios de Precio para Portafolio Óptimo (Base 100)')\n",
    "plt.xlabel('Días')\n",
    "plt.ylabel('Valor Portafolio')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"simulacion_monte_carlo_portafolio_optimo.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 2. Cálculo de Drawdown máximo para portafolio conservador y Distribuciones porcentuales               \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "print(\"Calculando Drawdown máximo para portafolio conservador...\")\n",
    "\n",
    "portafolio_conservador_ret = daily_returns.dot(results['Weights'][np.argmax(results['Sharpe'])])\n",
    "portafolio_conservador_idx = (1 + portafolio_conservador_ret).cumprod()\n",
    "\n",
    "running_max = portafolio_conservador_idx.cummax()\n",
    "drawdown = (portafolio_conservador_idx - running_max) / running_max\n",
    "\n",
    "max_drawdown = drawdown.min()\n",
    "max_drawdown_date = drawdown.idxmin()\n",
    "\n",
    "print(f\"Drawdown máximo: {max_drawdown:.2%} en fecha {max_drawdown_date.date()}\")\n",
    "\n",
    "# Graficar Drawdown\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(drawdown, color='red')\n",
    "plt.title(f'Drawdown máximo del Portafolio Conservador: {max_drawdown:.2%} en {max_drawdown_date.date()}')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.xlabel('Fecha')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"drawdown_maximo_portafolio_conservador.png\")\n",
    "plt.close()\n",
    "\n",
    "#Distribución porcentual del portafolio máximo Sharpe\n",
    "# Leer los pesos desde el archivo\n",
    "df = pd.read_csv(\"portafolio_max_sharpe.csv\", index_col=0)\n",
    "labels = df.index.tolist()\n",
    "sizes = (df['Peso'] * 100).round(2).tolist()\n",
    "\n",
    "# Definir colores\n",
    "colors = ['red', 'yellow', 'pink', 'brown', 'orange', 'blue', 'green', 'purple', 'cyan', 'gray']\n",
    "\n",
    "# Explode para destacar la acción con mayor porcentaje\n",
    "max_index = sizes.index(max(sizes))\n",
    "explode = [0.1 if i == max_index else 0 for i in range(len(sizes))]\n",
    "\n",
    "# Crear gráfico\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, explode=explode,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribución porcentual del portafolio máximo Sharpe')\n",
    "plt.savefig(\"Distribución porcentual del portafolio máximo Sharpe.png\")\n",
    "plt.close()\n",
    "\n",
    "#Distribución porcentual Mín Varianza\n",
    "# Leer los pesos desde el archivo\n",
    "df = pd.read_csv(\"portafolio_min_varianza.csv\", index_col=0)\n",
    "labels = df.index.tolist()\n",
    "sizes = (df['Peso'] * 100).round(2).tolist()\n",
    "\n",
    "# Definir colores\n",
    "colors = ['red', 'yellow', 'pink', 'brown', 'orange', 'blue', 'green', 'purple', 'cyan', 'gray']\n",
    "\n",
    "# Explode para destacar la acción con mayor porcentaje\n",
    "max_index = sizes.index(max(sizes))\n",
    "explode = [0.1 if i == max_index else 0 for i in range(len(sizes))]\n",
    "\n",
    "# Crear gráfico\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, explode=explode,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribución porcentual del portafolio_min_varianza')\n",
    "plt.savefig(\"Distribución porcentual del portafolio_min_varianza.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "# 3. Análisis simple de liquidez usando Volumen promedio diario \n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "print(\"Analizando liquidez promedio diaria de activos...\")\n",
    "\n",
    "volumen_promedio = daily_returns.copy()\n",
    "volumen_promedio[:] = 0  # inicializar\n",
    "\n",
    "# Extraer volumen de los datos descargados\n",
    "try:\n",
    "    volumen_data = data['Volume']  # data descargada con yf.download\n",
    "    volumen_promedio = volumen_data[list(tickers.values())].mean()\n",
    "    volumen_promedio.index = tickers.keys()\n",
    "except Exception as e:\n",
    "    print(\"No se pudo cargar volumen, revisa que 'data' contenga la info de volumen.\")\n",
    "    volumen_promedio = pd.Series(index=tickers.keys(), data=np.nan)\n",
    "\n",
    "# Mostrar tabla simple de volumen promedio\n",
    "print(\"\\nVolumen promedio diario (millones de acciones):\")\n",
    "print((volumen_promedio / 1e6).round(2))\n",
    "\n",
    "# Guardar volumen promedio en CSV\n",
    "volumen_promedio.to_csv(\"volumen_promedio_diario.csv\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=volumen_promedio.index, y=volumen_promedio.values)\n",
    "plt.title(\"Volumen Promedio Diario por Activo\")\n",
    "plt.ylabel(\"Volumen Promedio (acciones)\")\n",
    "plt.xlabel(\"Activo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"volumen_promedio_diario.png\")\n",
    "plt.close()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# Fin del Script\n",
    "\n",
    "print(\"✅ Todos los gráficos y matrices fueron generados correctamente.\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
